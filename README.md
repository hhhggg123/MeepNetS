# MeepNetS
Multimodal fusion Deep neural Network based on Self-supervised learning

Due to the complexity of data analysis and the difference between the different types of data, the current integrated analysis strategy has problems such as lack of effective pre-trained models for pathological image data and multi-omics data modalities, poor cross-cancer generalization performance, low model accuracy, low operational efficiency or inability to generalize to multi-omics datasets. Here, we propose a new multimodal analysis model called MeepNetS, which can effectively extract pathological image features by Self-supervised learning model, and obtain better results than other state-of-the-art models.
